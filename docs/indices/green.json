[
  {
    "objectID": "cddcb5d245484a0aaff1b60c752ae2b1",
    "u": "https://pii.tymyrddin.dev/",
    "t": "Protecting your PII ",
    "c": "Protecting your PII  The Internet is rife with adversaries that are after our identity and information, and readily provides vulnerabilities that can be exploited for that. Some of the most common threats are software attacks, identity theft, theft of information, sabotage, information extortion, surveillance, censorship and data abuse for ever more profits and control. Many journalists, activists and researchers work have been exploited due to its vulnerable structure, sometimes with severe (life threatening) consequences. Goals Avoiding surveillance Circumventing censorship Infosec goals Safer browsing Introduction Use a secure browser that protects your privacy Private browsing Take control of your browser Minimise your browser plugins Switch your user agent Cookie monsters Federated Learning of Cohorts (FLoC) Am I NOT FloCed? Anonymising traffic Introduction Tunnelling SSH tunnels explained Use a VPN service VPN Fail open DNS leaks Digital mixing Using Tor Using I2P Chaining Creating a VPN with SSH and tun Change MAC address Renew IP lease Change nickname Edit hosts file Securing email Introduction Use secure email services Use email securely Detecting fake emails and phishing Using GNU PG ‘;–have i NOT been pwned? E2EE messaging Introduction Use a secure messaging service File transfer Introduction Choose file sharing services Torrenting (P2P) Uploading files to a server Checking integrity of downloads (Linux) Data in rest Introduction Metadata Introduction Clean machine with BleachBit Remove metadata with hex editors Metadata Anonymisation Toolkit 2 (MAT2) Edit exif metadata in images Web applications Introduction UnFloC your site Apache Make the site GDPR compliant Secure file uploads from users",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "01ec7d02c338a58b068c703031af7ac5",
    "u": "https://pii.tymyrddin.dev/docs/circumventing-censorship",
    "t": "Circumventing censorship ",
    "c": "Circumventing censorship  Increasingly, states have adopted wide-scale internet blocking as a technical resource for extending their practice of information control into the online world. The answer has been the development of circumvention tools for Seeking, reading and disseminating unauthorised content Creating unauthorised content Distributing unauthorised content Leaking confidential or otherwise privileged information Internet malware can be developed and installed by governments to attack, monitor, or disrupt dissident computer systems and communication. Malware specifically targeted at a regional, racial, or language group is very difficult to intercept and identify by any anti-malware products available today and I wouldn’t put it past regimes to try to create a range of fake circumvention tools under established names. One might also expect government authorities to profile users of circumvention tools. When circumventing censorship, it is important to do this while anonymised and protected. The resources and continuous effort required to constantly evade blocking activities while remaining anonymous is not to be underestimated, and requires careful planning and implementation. Which tools to use?  Just a getting started. As with anonymising traffic, it depends on where you are, what the state adversary makes available in terms of resources and what the consequences of discovery in your country may be. Method Description DPI Cost for censor Circumvention IP blocking A certain IP address is denied No Low Find proxies that have access DNS filtering and redirection DNS doesn't resolve domain names or returns incorrect IP addresses No Low Find a domain name server that resolves domain names correctly or bypass DNS if the IP address is obtainable from other sources and is not blocked. ( Modify hosts file or type the IP address instead of the domain name) URL filtering Permits or denies access to specific websites based on information contained in an URL list Yes Medium Use escaped characters in the URL , or use encrypted protocols such as VPN and Tor Packet filtering TCP packet transmissions are terminated when a certain number of controversial keywords are detected Yes Low Use encryption, such as VPN and Tor Man-in-the-middle attack A root certificate is replaced with a self-signed certificate in the state by its agencies Low Websites implementing HSTS TCP connection reset If a previous TCP connection is blocked by the filter, future connection attempts from both sides will also be blocked for up to 30 minutes. Depending on the location of the block, other users or Web sites may be also blocked if the communications are routed to the location of the block. This was used by the Great Firewall of China in 2007 . I seriously doubt is still in use. Yes Medium Ignore the reset packet sent by the firewall VPN and Tor blocking A firewall is able to \"learn, discover and block\" the encrypted communications methods used by a number of different VPN systems, and connection is terminated Yes High Add a form of data obfuscation (steganographic coding); Tor: Pluggable Transports",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "c371d28da4978c2f01a2245d0d1285ad",
    "u": "https://pii.tymyrddin.dev/docs/webapplication/floced-sites",
    "t": "UnFloC your site ",
    "c": "UnFloC your site  FLoC requires that a website provide an explicit HTTP response header if it wants to opt out of the program. Google is counting on webmasters to not be bothered with this task. Google is counting on webmasters to not be bothered with this task. Be bothered: website or blog  In order to opt out a website out of the FLoC network, add a custom HTTP response header to all websites to be served with each request. This comes in the form of a Permissions-Policy header, with the following syntax: Permissions-Policy: interest-cohort=() Wordpress  For WordPress there is an open-source plugin, Disable FLoC , that will add the necessary Permissions-Policy headers to the WP. An alternative is the paid Really Simple SSL pro plugin that will allow setting more Permission-Policy headers. nginx webserver  If you have access to your webserver, for nginx use the add_header directive (and then restart nginx): server { location / { add_header Permissions-Policy interest-cohort=(); ... } } OpenLiteSpeed webserver  If you have access to your webserver, for the OpenLiteSpeed web server, add the FLoC header by editing vhost.conf located in /usr/local/lsws/conf/vhosts/[some_application]/vhconf.conf , for example context / { location $DOC_ROOT allowBrowse 1 note This header disables FLoC extraHeaders set Permissions-Policy interest-cohort=() } and do a graceful restart of OpenLiteSpeed. Apache  For Apache web server, add the custom header in the configuration file: <IfModule mod_headers.c> Header always set Permissions-Policy: interest-cohort=() </IfModule>",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "1bf4296497984a47f54cf2049bad469c",
    "u": "https://pii.tymyrddin.dev/docs/browsing/floc",
    "t": "Federated Learning of Cohorts (FLoC) ",
    "c": "Federated Learning of Cohorts (FLoC)  Third-party cookies are going extinct now that many browsers block third-party cookies, but that doesn’t mean Google (and others) will respect our privacy. Google started an experiment called FLoC (Federated Learning of Cohorts). It runs in Google’s Chrome browser and tracks a user’s online behaviour. How it works  It runs in Google’s Chrome browser. SimHash is used to create user IDs and assign people to cohorts. FloC assigns the browser history an anonymised ID The ID is added to a group of other browsers with similar behaviors called a cohort. IDs are recalculated on a weekly basis, providing a new summary of their online behaviour every week. Opt out  This all happens on the local computer, our data wouldn’t get stored on a server, but it lives and runs in the code. No opt-in or opt-out for users as long as one uses Google Chrome. Do not use Google Chrome. Use one of the alternative browsers . If you do have to use Chrome, use DuckDuckGo’s Chrome Extension . It disables FLoC tracking within the browser. Whether Google will disable it in the future or the browser will ignore it remains to be seen.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "a133084c5241889fd4bd4629c8db6f73",
    "u": "https://pii.tymyrddin.dev/docs/webapplication/secure-file-uploads",
    "t": "Secure file uploads from users ",
    "c": "Secure file uploads from users  If your site allows users to upload a file: A file upload vulnerability can have a crucial impact because code can be executed on the server or the client. The uploaded file can be misused to exploit other vulnerable components of an application or trigger vulnerabilities in defective libraries while the file exists on the same machine. Uploaded files that threat actors can use could contain Command and control (C&C) server information, directions for harassment or violence or steganographic materials. Only allow extensions that are required for the application’s functionality. Check that it: Verifies the file type without trusting the Content-Type header, which can be spoofed. Enforces file name length and size limit, and changes the file name while hosting it on a server. If files are publicly available, check that it uses handler mapping to map ID to filename within the application. If possible, it runs files through a sandbox or antivirus.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "87d63f7637adadfc3dc32f4756caeb8e",
    "u": "https://pii.tymyrddin.dev/docs/e2ee/messaging-apps",
    "t": "Use a secure messaging service ",
    "c": "Use a secure messaging service  A secure messaging service is a critical tool for private and secure communications. In most countries, it is safe to assume that telecoms are recording all SMS message traffic. Signal is not as strong on privacy as it is on security. It collects some metadata, and relies on central servers to manage message flow and hold the metadata it does collect. Session is a fork of Signal. No geolocation data, device data, or metadata is collected. The Session network is decentralized, with no single point of failure, and no main server for bad guys to hack. Session moves messages using an onion routing system. And make it the default SMS messenger.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "8960431482c2b64436ca8490055a8702",
    "u": "https://pii.tymyrddin.dev/docs/email/email-use",
    "t": "Use email securely ",
    "c": "Use email securely  Invented by Ray Tomlinson, email first entered limited use in the 1960s and by the mid-1970s had taken the form now recognized as email. It evolved, and so did its parasites: Email “spam”. A number of effective anti-spam techniques now largely mitigate the impact of spam by filtering or rejecting it for most users, but the volume sent is still very high, and increasingly consists not of advertisements, but malicious content or links. Phishing emails continue to be one of the most common initial attack vectors employed by attackers for malware delivery. Attacking the human element continues to be extremely effective. To infect a system, the attacker simply has to persuade a user to click on a link or open an attachment. Email spam and phishing methods typically use spoofing to mislead the recipient about the true message origin. Laws in many countries either allow or have loopholes in an existing law that allow the government to access stored emails without a warrant, and intelligence agencies can do and actually do so. Internet as well as intranet email may travel and be stored on networks and computers without the sender or the recipient having any control. During the transit time it is possible that third parties read or even modify the content. The ease and impersonality of email communications mean that the social norms that encourage civility do not exist and may be forgotten. Flaming, bullying, … To stay sane: Do not use public computers to access email with sensitive information. If you are not in a safe neighbourhood, use a VPN or Tor anonymity network to encrypt traffic from the user machine to a safer network. Use a privacy-focused email application (make sure not to use your own name or other personal information) GPG, PGP, SMEmail, can be used for end-to-end message encryption.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "0cedcf20c073dd2feb6f9f5abef40fa3",
    "u": "https://pii.tymyrddin.dev/docs/browsing/cookies",
    "t": "Cookie monsters ",
    "c": "Cookie monsters  Third party cookies store our data on a server, a major privacy concern. For not accepting third party cookies: Firefox: Preferences -> Privacy -> Accept third-party cookies -> Never. Chrome (also chromium): Settings -> Show advanced settings… -> Content settings -> Block third-party cookies and site data. When changing the default cookie “lifetime” from “Keep until: they expire” to “Keep until: I close Firefox”, Firefox changes any persistent cookies that sites set to session cookies. To allow a site to set a persistent cookie, an exception (site permission) must be made. For clearing cookies on exit: Firefox/Tools -> Options -> Privacy -> “Use custom settings for history” -> Cookies: Keep until: “I close Firefox”. Chrome (also chromium): Settings -> Show advanced settings … -> Content settings -> Keep local data only until you quit your browser. When turning on the clearing of history at shutdown and include cookies, a completely separate process runs which does not pay any attention to cookie lifetime or exceptions (site permissions). It just nukes them all. Note that some cookies might survive clearing at shutdown if they are encoded into the session history file, the one Firefox uses to restore previous session windows and tabs.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "9251d26dc42b5433d7d61cfbaf5c041f",
    "u": "https://pii.tymyrddin.dev/docs/traffic/edit-hosts-file",
    "t": "Edit hosts file ",
    "c": "Edit hosts file  The hosts file is a system file on a device that lets you map specific domain names to an IP address. If you want to add new entries to the hosts file, you’ll need the IP address of the server that you want to map a hostname to. XXX.XXX.XXX.XXX some.domain.name Workstations and PC’s  Linux: Edit hosts file macOS: Edit hosts file Windows: Edit hosts file Phones  Android: Edit hosts file iOS: Edit hosts file",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "b517e45536d26c242fce886299399a9f",
    "u": "https://pii.tymyrddin.dev/docs/metadata/metadata-images",
    "t": "Edit exif metadata in images ",
    "c": "Edit exif metadata in images  Photos, and images in general, contain metadata. For photos this includes how large the picture is, colour depth, resolution, the date and time when it was created, the GPS coordinates of the location they were taken at, camera shutter setting details, and possibly even the name of the program used to edit them. Workstations and PC’s  Edit exif metadata in images on Linux Edit exif metadata in images on Windows Edit exif metadata in images on macOS",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "797aa6684c820a9ffadc215e795615b1",
    "u": "https://pii.tymyrddin.dev/docs/e2ee/readme",
    "t": "Introduction ",
    "c": "Introduction  End-to-end encryption (E2EE) is a defence against MitM attacks. Most E2EE systems are secure against only the weakest passive adversaries, breakable not by cryptanalysis of underlying cryptographic algorithms but by flawed system designs and security assumptions. Unencrypted metadata and access patterns make these systems susceptible to inference attacks. And recently made laws seem to have been made to prepare the way for agencies to legitimately gather encrypted data via backdoors and ghost protocols. The Infosec goals of E2EE are: Confidentiality: Only the two participants of pair-wise messaging or legitimate group member of group messaging can see the message plaintext. Integrity: If a message is received and successfully validated, then it was indeed sent by the given sender, i.e., other users cannot plant messages into it, and they can not modify it. Use a secure messaging service .",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "15cea650d7dc5090895c44fd21f51944",
    "u": "https://pii.tymyrddin.dev/docs/traffic/vpn-ssh-tun",
    "t": "Creating a VPN with SSH and tun ",
    "c": "Creating a VPN with SSH and tun  Not all programs have the ability to use a SOCKS proxy, while what is really needed is an all-encompassing proxy, one that just takes all outgoing and incoming traffic and sends it over that secure encrypted link. In effect, a secure VPN . In the situation described in SSH explained root access to a remote machine running an ssh server, a SSH client, install the tun kernel module locally and remotely. # modprobe tun To establish a new network interface on both sides of the connection, ‘’tun0’’, locally run the command: # ssh -w 0:0 -f -C -q -N root@host.tld And: # ifconfig tun0 10.0.0.200 pointopoint 10.0.0.100 SSH into the remote machine, and run these commands: # ifconfig tun0 10.0.0.100 pointopoint 10.0.0.200 # ping -c 3 10.0.0.200 If you get a ping response, it works. Routing your traffic through the remote machine, requires setting it up to enable packet forwarding and configuring iptables to act as a gateway (for which William Budington has written a script ( Download sharedconnection.sh script ) that can serve as a starting point). Set up routing tables locally to direct all traffic (except the traffic that is still needed to keep the tun0 interface alive!) through the tun0 interface (in this case for a router with IP address ‘’192.168.0.1’’, and default interface ‘’eth0’’): # route add host.tld gw 192.168.0.1 eth0 # route del default gw 192.168.0.1 eth0 # route add default gw 10.0.0.100 tun0 All outbound and incoming traffic is now routed through the remote machine. Get friends to use it as well, this reduces fingerprinting risks for all involved. It is also possible to set up iptables to forward all traffic through a socks proxy without remote root and the tun module. IOW, more to follow …",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "02cf62a3e927cf60b98425958b936589",
    "u": "https://pii.tymyrddin.dev/docs/infosec-goals",
    "t": "Infosec goals ",
    "c": "Infosec goals  Information security, sometimes shortened to InfoSec, is the practice of preventing unauthorized access, use, disclosure, disruption, modification, inspection, recording or destruction of information. Its goals are Plausible Deniabilty seeks to prevent the disclosure of information by presenting an argument about the knowledge a given individual has. This is a second order game, at least one level removed from direct protection of information. Data Confidentiality is the protection of information in the system so that an unauthorized person cannot access it. Confidentiality is maintained through restrictions or limiting access. Data Integrity is the protection of system data from intentional or accidental unauthorized changes. Maintaining integrity can be possible through the restriction of editing, liability, and modifying information. Data availability is ensuring the reliability of the access to information. The ways to maintain availability: access procedures, back-up or also duplication, maintenance of hardware and network connection. Forward secrecy aims to prevent future exploits and security breaches from compromising current or past communication, information or data by isolating each transaction’s encryption. Post compromise security is the protection of users’ data after the encryption key has been compromised. Perfect secrecy is based on statistics and probabilities. A ciphertext maintains perfect secrecy if the attacker’s knowledge of the contents of the message is the same both before and after the adversary inspects the ciphertext, attacking it with unlimited resources.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "f0b2ac0c4892478f88c1350fb3b5afdc",
    "u": "https://pii.tymyrddin.dev/docs/webapplication/gdpr",
    "t": "Make the site GDPR compliant ",
    "c": "Make the site GDPR compliant  Although supposedly going extinct, third party cookies are still in use by, for example, many Wordpress (feature adding) plugins. Wordpress covers around 30% of the websites on the internet. Make the site GDPR compliant with, for example for Wordpress, plugins like Complianz – GDPR/CCPA Cookie Consent or WordPress compliance with GDPR/ePR and CCPA . Both give a list of all third-party cookies, including the hidden ones, being transmitted by the site to visitors. **",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "1ba715428ee0ce118555c0ffb27eefc4",
    "u": "https://pii.tymyrddin.dev/docs/traffic/digital-mixing",
    "t": "Digital mixing ",
    "c": "Digital mixing  In the eighties, digital mixes (sometimes called mix networks or mixnets) to achieve a higher level of anonymity with personal communication appeared. Digital mixing uses a similar system as routing, but it adds several layers in the connection between the sender and receiver of the communication. The layers are created using public key cryptography. Using digital mixing is comparable to sending a letter encased in four envelopes pre-addressed and pre-stamped with a small message reading, please remove this envelope and repost. Note: Mixnets are not designed to disguise the fact that you are using a mix network. If an adversary can simply lock you up for using anonymity tools, you need to disguise your use of anonymity tools. If Alice wants to send a message to Bob, without a third person being able to find out who the sender or recipient is, she would encrypt her message three times with the aid of public key cryptography. She would then send her message to a proxy server who would remove the first layer of encryption and send it to a second proxy server through the use of permutation. This second server would then decrypt and also permute the message and the third server would decrypt and send the message to the intended recipient. Threshold batching  A mix node must collect more than one message before sending any out - otherwise the node is behaving as an onion router node with a time delay. The more messages collected, the more uncertainty is introduced as to which message went where. Using this threshold batching strategy to solve a lack of messages can make the period between the sending and the eventual receiving of the message long, like several hours, depending on the amount of messages deemed critical. This system is thought effective because as long as the three successive recipients, the re-senders, send enough messages to different mixnodes it is impossible for a third person like an ISP (and government (law enforcement) agencies) to find out what message was originally sent by whom and to whom. Mixing is specifically designed to provide security even if an adversary can see the entire path. Vulnerabilities  Only works if the resenders send enough messages (at any given moment and during a set amount of time). Because (most) nodes, the resending servers, do not send enough messages at the same time, digital mixing could be vulnerable to statistical analysis such as data mining by governments or government policing and intelligence agencies. The use of public key cryptography in itself is not very fast, and has its own vulnerabilities.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "f1261a8faf965d0de2342999d2bfd830",
    "u": "https://pii.tymyrddin.dev/docs/filetransfer/sftp",
    "t": "Uploading files to a server ",
    "c": "Uploading files to a server  FTP is an insecure protocol in the sense that it sends your credentials in plain text to the server. Do not use. Secure File Transfer Protocol (SFTP) solves this problem by using the underlying SSH tunnel to transfer files. This ensures that all the traffic - credentials, server commands and files - are encrypted before sending. Since an intercepting computer hasn’t got the encryption key, it can know nothing about the data transferred. But, your ssh host key can be used to fingerprint you by connecting to port 22 of your IP to verify that you are using the same machine as some other previous IP, either at your ISP or over VPN, so do not use it for distributing unauthorised content. And, you can additionally, protect SSH with MFA. SSH but make it Tailscale - Mac, iOS, Windows, Android or Linux, Raspberry Pi. Free for personal use on up to 20 devices.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "4f89d4719b974e4c5eec01b4eb29e31c",
    "u": "https://pii.tymyrddin.dev/docs/browsing/browser-plugins",
    "t": "Minimise your browser plugins ",
    "c": "Minimise your browser plugins  There are a lot of browser extensions and plug-ins supposedly protecting users against tracking: The presence or absence of plug-ins provides a large amount of information. NavigatorPlugins.plugins (JS) is still supported by some browsers. It returns a PluginArray object, listing the Plugin objects describing the plugins installed. A lot plug-ins themselves will happily provide websites with a large amount of identifying information about a user, including the list of installed fonts, CPU model and speed, IP addresses, username, hostname, etc. Plus plug-ins can also have their own data and cookie stores, that they allow websites to manipulate. Apparently it is even possible to use the NoScript plugin to gather information about what sites, or files, a user accessed while in a private browsing session and also whilst using the TOR browser.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "b74a2a1dea372a3fe8b7fcd30dd6ff99",
    "u": "https://pii.tymyrddin.dev/docs/traffic/chaining",
    "t": "Chaining ",
    "c": "Chaining  Suppose you visit a website with a torified Browser. Tor processes the traffic. Your adversary uses a vulnerability to remotely execute code. An adversary who can talk to the control port, can use Tor’s getinfo address, setconf a proxy or alternate directory authorities or bridges, listen to events (including log events) that give away details that can be correlated. Not only an end to end correlation attack, many more vulnerabilities exist. Any successful attack against Tor on a Tor based anonymity operating system will naturally deanonymise the user. Some of the attacks can be protected from by chaining. Whonix uses this approach . With some notes … For deciding whether to use chaining or not, and if so, whether to use TorPlusVPN (torproject) for combining tunnels with Tor , summarising: It all depends on where you live, what you do, what your resources are, and what skills you have. You -> VPN/SSH -> Tor  Routing Tor through VPN/SSH services might prevent your ISP etc from seeing that you’re using Tor (VPN/SSH Fingerprinting). Using VPN’s may or may not make you stand out as much, as in some countries replacing an encrypted Tor connection with an encrypted VPN or SSH connection (which is what it will look like), will be suspicious as well. SSH tunnels may make you stand out even more. It also prevents Tor from seeing who you are behind the VPN/SSH. If an adversary breaks Tor and learns the IP address your traffic is coming from, and your VPN/SSH really does not watch, does not remember, and makes magically sure nobody else is watching either, you’ll be safer. You -> Tor -> VPN/SSH  Routing VPN/SSH services through Tor hides and secures your Internet activity from Tor exit nodes (a major vulnerability because some governments create exit nodes to do just that). You are still exposed to VPN/SSH exit nodes and will want to pay for the VPN anonymously (cash in the mail [mind your fingerprint and printer fingerprint], Liberty Reserve, well-laundered Bitcoin, etc). This is impossible to do without using virtual machines and is not easy to set up. It also creates a bottleneck where all your traffic goes, making correlations easy and the VPN/SSH can over time build a profile of everything you do, and over time de-anonymise your traffic.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "a1770718849ef0752def8e5210931dfc",
    "u": "https://pii.tymyrddin.dev/docs/email/check-mail",
    "t": "Detecting fake emails and phishing ",
    "c": "Detecting fake emails and phishing  Fake emails  View the header info. Pay attention to the email address of a sender. It may imitate a legitimate sender. With only few characters altered or omitted, cybercriminals will often use an email address that closely resembles one from a reputable source. Look closely at the content: Hover your cursor over any links in the body of an email. Links not matching the text that appears raise a red flag. So does the use of URL shortening services. Email clients can be viewed in simple text instead of html, so one never forgets to do this. Poor grammar and sentence structure, misspellings, and inconsistent formatting can be other indicators of a possible phishing attempt. An unsolicited email requesting a user download and open an attachment is a common delivery mechanism for malware, even when it seems to come from a friend, or an employeur. A false sense of urgency or importance to help persuade a user to download or open an attachment without examining it first, completes this picture. Do not. Verify message source. Check the reply email. Reply and wait for the result. Phishing  Be wary of emails asking for confidential information. Don’t get pressured into providing sensitive information. Phishers like to use all kinds of social engineering. Learn what you can about it. Check a website’s privacy policy, especially whether it will or will not sell its mailing list. If so, do not register. Watch out for generic-looking requests for information. Never submit confidential information via forms embedded within email messages. Never use links in an email to connect to a website unless you are absolutely sure they are authentic. View header information  To view the header information of an email message, select the message, then click on some menu to view all headers. The Return-path is allegedly the e-mail address of the sender, although that is not a reliable method for identifying the sender because most adversaries use any return e-mail address that they can find on for the purpose created lists. The Received line is a bit more reliable, because that contains the IP address of the location from where the message was sent. That is, of course, unless an adversary hacked into an e-mail server or is using a relay server to disguise the true source of the message.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "476b4f0dfb9d04de1dc5d2be524c8b2b",
    "u": "https://pii.tymyrddin.dev/docs/email/email-services",
    "t": "Use secure email services ",
    "c": "Use secure email services  Mailfence , Belgium, provides a full suite of services, Messaging, s, Calendars, Groups, and Document storage. It can easily replace the G suite. It is a secure email suite that offers end-to-end encryption (through PGP support) and works with different email clients. There is some logging of IP address and some other data, and the code is not open source. Tutanota , Germany, is a small but serious player among secure email providers. It uses a hybrid encryption system that avoids some drawbacks of PGP, and is protected by the GDPR and other pro-privacy EU regulations. So, it does not work with PGP and there is no way to import existing emails (yet). ProtonMail , Switzerland, uses PGP encryption standards for email and stores all messages and attachments encrypted at rest on Swiss servers. ProtonMail has a unique feature for “self-destructing messages” and they have also added address verification and full PGP support. Articles  Reddit: Court forces mail provider Tutanota to perform a surveillance function Twitter: ProtonMail logging one of its users and providing IP address logs to French authorities Reading that carefully, if the message had already been encrypted and the IP address had been that of a VPN, these cases would not exist.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "cd83113c9922961eb029b1f4713eb2d7",
    "u": "https://pii.tymyrddin.dev/docs/data/readme",
    "t": "Introduction ",
    "c": "Introduction  Operating systems and applications can always be reinstalled, but your data is unique, making it the most important thing on your computer or network to protect. Set permissions on the data files and folders. Some data is confidential; not only do you not want to lose it, you don’t want others to even view it without authorisation. Use removable storage for the most sensitive data (such as database and key files for password managers) Use file encryption Use disk encryption Assume data loss is inevitable. It’s not a matter of if, it is a matter of when. You best protect your data with a solid backup strategy. Make a backup of your entire system or synchronise files with a remote system If you make a backup of a system for the first time to be able to restore a system from (the whole point of it), test it with an actual restore. Having done so helps in staying calm when the **** hits the fan. You may wish to shred and delete data and not have it found by anyone. Keep your authentication data in a password manager (on a local usb stick) Workstations and PC’s  MacOS (Catalina) data Windows 10 data GNU/Linux (Debian/Ubuntu 22.04) data Phones  Android (Galaxy 5,22,50) data iOS (7-10) data",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "862c8e13d2f21595c41033a1fbcf4bf7",
    "u": "https://pii.tymyrddin.dev/docs/traffic/vpn",
    "t": "Use a VPN service ",
    "c": "Use a VPN service  Internet providers are collecting your browsing data and handing this over to third parties (US, UK, Australia, and much of Europe). Public Wi-Fi remains a serious threat with adversaries targeting unsuspecting users. Many streaming services and websites restrict content to certain geographic locations. A VPN allows you to bypass such restrictions. A VPN will encrypt the connection and make the traffic unreadable. No logs policy  Meaning, not logging traffic, DNS requests, timestamps, bandwidth, IP address. NordVPN , Panama Mullvad , Sweden IVPN , Gibraltar Surfshark VPN , Netherlands Logs timestamps and bandwidth  Does not log directly identifiable information. ExpressVPN Papers  An Analysis of the Privacy and Security Risks of Android VPN Permission-enabled Apps (pdf)",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "5ae0f0c297f68af5c34b2bc96a5c3f76",
    "u": "https://pii.tymyrddin.dev/docs/traffic/ssh",
    "t": "SSH tunnels explained ",
    "c": "SSH tunnels explained  Secure Shell (SSH) can be used to securely acquire and use a remote terminal session and has other uses as well. You can use SSH to tunnel traffic, transfer files, mount remote file systems, and more. SSH also uses strong encryption and you can set your SSH client to act as a Socks proxy. Once you have, you can configure applications on your computer – such as your web browser – to use the Socks proxy. The traffic enters the Socks proxy running on your local system and the SSH client forwards it through the SSH connection – this is known as SSH tunneling. This works similar to browsing the web over a Virtual Private Network (VPN). From a web server perspective, traffic appears to be coming from the SSH server. The traffic between source and the SSH server is encrypted, so you can browse over an encrypted connection as you could with a VPN. You must configure each application to use the SSH tunnel’s proxy. SSH tunnels can be created in several ways using different kinds of port forwarding mechanisms. See examples in Workstations and PC’s  Linux: Use ssh tunnels macOS: Use ssh tunnels Windows: Use ssh tunnels Phones  Android: Use ssh tunnels iOS: Use ssh tunnels",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "8d0340f5829323d1e45aa896c067477b",
    "u": "https://pii.tymyrddin.dev/docs/filetransfer/readme",
    "t": "Introduction ",
    "c": "Introduction  File sharing involves using technology that allows internet users to share files that are housed on their individual computers. Peer-to-peer (P2P) applications are some of the most common forms of file-sharing technology and introduce security risks that may make (some of) our information visible. Choose file sharing services Check integrity of downloads Uploading files to a server Torrenting (P2P)",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "48528c763195bb59f8c08b9a8627b1c2",
    "u": "https://pii.tymyrddin.dev/docs/filetransfer/torrenting",
    "t": "Torrenting (P2P) ",
    "c": "Torrenting (P2P)  Torrents are file downloads from peer-to-peer networks: Video games, films, music, photos, and other forms of media. It works by allowing people to download small portions of data from distributed sources, and these portions are transmitted from one user to the next. The most common way to use torrents is through a special file that uses the .torrent file extension. Within the file are directions for how to share specific data with other people. These files can be downloaded from a torrenting website. Malware is one of the most prevalent threats you can encounter on torrenting websites. Anyone downloading a file from a torrenting website has no idea what the file contains. A film, or a malware. When you download and share a torrent file, the file’s creator becomes active and can track your online actions. If the file’s original uploader is an adversary, they can make use of this information. Run antivirus software on the file you download before opening it. Anonymise your traffic. Set up and use a sandbox (can do with a VM) for it.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "71ca4c6e45fe7fdf0f3b44e19aa6f93e",
    "u": "https://pii.tymyrddin.dev/docs/browsing/readme",
    "t": "Introduction ",
    "c": "Introduction  Keyloggers and other malware can be installed via a web page script which exploits a browser vulnerability. The program will automatically be launched when a user visits an infected site. Compromising a browser is relatively easy, and it is cross-platform, hence an often chosen target. BeEF & other browser exploits, when not using browser vulnerabilities, rely on javascript. Phishing (and therefore browsing) is one of the most low cost attack vectors in systematic attacks and data theft, with all of its consequences. Safer browsing is a good investment all around. The way in which browsers are configured (especially the browser plugins used), together with details of the Operating System in which the browser runs, allows its users to be uniquely identified and tracked. Third-party cookies are going extinct now that many browsers block third-party cookies , but that doesn’t mean Google (and others) will respect our privacy. Google started an experiment called Federated Learning of Cohorts (FLoC) . It runs in Google’s Chrome browser and tracks a user’s online behaviour. Plus that browsers (for performance reasons) prefetch exposing users to more security risks by downloading more pages, or from un-requested sites (additionally compounded as drive-by downloads become more advanced and diverse). Use a secure browser that protects your privacy Use private browsing Minimise your browser plugins Take control of your browser Switch your user agent (also useful when doing reconnaissance). Fail  Am I FloCed?",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "b7027c9131d31b4822d6cb8e5135ccc4",
    "u": "https://pii.tymyrddin.dev/docs/browsing/browsers",
    "t": "Use a secure browser that protects your privacy ",
    "c": "Use a secure browser that protects your privacy  Brave is fast, secure, and privacy-focused by default. It has a built-in ad blocker and browser fingerprinting protection, while also giving you access to numerous add-ons and extensions. Brave opposes FLoC Ungoogled Chromium browser is an open source project to provide a Chromium browser, without the Google privacy issues. Bromite is a Chromium-based browser for Android only (no desktop support). It comes with some great features by default, including ad blocking and various privacy enhancements. LibreWolf is a fork of Firefox focused on privacy, security, and freedom, only available for desktop operating systems.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "6a428223c27127e6ab1893b0d0c06930",
    "u": "https://pii.tymyrddin.dev/docs/traffic/i2p",
    "t": "Using I2P ",
    "c": "Using I2P  I2P is a Distributed Peer to Peer Anonymous Network Layer that is strictly message-based. It allows you to send data between computers running I2P anonymously with multilayer end-to-end encryption. The name I2P derived from Invisible IRC Project (IIP) which was one of FreeNet’s sister projects. I2P focuses exclusively on internal communication and not on proxying to the regular internet. I2P uses so-called garlic routing which involves clumping packets together into bigger packets. The combination of garlic routing, multilayer encryption -even the end points (“destinations”) are cryptographic identifiers- and random padding on packets makes analysis of the content and detection of the origin of I2P traffic by third-party observers highly impractical if not nearly impossible. The best use for I2P is for peer to peer file sharing and communication. Garlic routing  Garlic routing is a variant of onion routing that encrypts multiple messages together to make it more difficult for attackers to perform traffic analysis. I2P implements a packet switched routing instead of circuit switched (like Tor). Tunnels are unidirectional, and Tor’s circuits are bidirectional. I2P bundles and encrypts in three places: For building and routing through tunnels (layered encryption) For determining the success or failure of end to end message delivery (bundling) For publishing some network database entries (dampening the probability of a successful traffic analysis attack) Tunnels  An I2P tunnel is a directed path through an explicitly selected list of routers. The first router that belongs to a tunnel is named gateway. The communication within a tunnel in unidirectional, this means that it is impossible to send back data without using another separated tunnel: //outbound tunnels// are those tunnels used to send messages away from the tunnel creator. //inbound tunnels// are those tunnels used to bring messages to the tunnel creator. Routers  There is no rigid distinction between a server and a pure client like there is in the Tor architecture. Information transits on network routers are able to decrypt only the respective layer. The information managed by each single node is composed by the IP address of the next router and the encrypted data to transfer. Layered encryption  I2P is end-to-end encrypted. No information is sent in clear or decrypted. Each node has an internal network address different from the network IP address (and is not used). During connecting (build up of tunnel) only the routing instructions for the next hop are exposed to each peer. During data transfer, messages are passed through the tunnel. Message and its routing instructions are only exposed to the endpoint of the tunnel. An additional end to end layer of encryption hides the data from the outbound tunnel endpoint and the inbound tunnel gateway. Each tunnel has an encryption layer to avoid unauthorized disclosure to peers inside the network. Installation  I2P is available for Windows, Mac OS X, GNU/Linux / BSD / Solaris, Debian /Ubuntu and Android. Download the bundle for your device and install. It is that easy.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "8750644da9c694bcbea322f8004beb1f",
    "u": "https://pii.tymyrddin.dev/docs/traffic/change-mac",
    "t": "Change MAC address ",
    "c": "Change MAC address  A MAC address identifies the device connected to a network and allows the network to track, restrict or allow access based on it. Routers identify and assign static IP addresses based on the MAC addresses of devices. Before you try to change the MAC address, you need to know the value that you want to use. Set the 2’s place bit (the “locally administered” bit) in the first byte, to differentiate it from a guaranteed globally unique MAC address. Usually the first three bytes an unicast MAC address is an “Organizationally Unique Identifier” (OUI) that the IEEE assigned to the manufacturer of your Ethernet device. Manufacturers are required to make sure they keep the last 3 bytes unique. Avoiding all of that knowledge, the MAC address generator tool can generate a valid address for you. Workstations and PC’s  Linux: Change MAC Address macOS: Change MAC Address Windows: Change MAC Address Phones  Android: Change MAC Address iOS: Change MAC Address",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "2800952bf91848d538f33f31fdb4c263",
    "u": "https://pii.tymyrddin.dev/docs/traffic/readme",
    "t": "Introduction ",
    "c": "Introduction  Network traffic visibility is the beginning of insecurity. Public networks like the internet are extremely vulnerable to traffic monitoring and surveillance. The most obvious way you can be tracked is by IP address. Packet headers identify the IP addresses of the recipient(s) and the packet routes can rather easily be tracked. There are many ways to change your IP address. And protecting ones IP address is not enough. Some applications and devices append extra headers to packets or other revealing data that can be correlated. Depending on your situation and on why you wish to remain anonymous, consider plausible deniability and installing local traffic monitoring to check for leaks in your traffic yourself. There is no better way for staying (relatively) calm under near-paranoia circumstances than not to have to depend on others. It is clear that browsing and email have the most low cost attack vectors for data theft and other hacks, tracking by corporations and for governmental spying. Learning about safer browsing and securing email is overall a good investment of time and energy. MAC addresses are used in the media access control protocol sub layer of the ISO/OSI model. It can be and often is used by networking equipment to track users. This means that proxy hopping on a network that has already authenticated your hardware is utterly useless. Changing MAC address is not that hard to do. And if you do, also renew your IP lease. If and when you connect in a public space over a wireless access point, anyone in the area with a packet sniffer can see your “nickname”. It can be changed . Admins of servers and websites need to be aware of applications they use that can give away information about identity and protect file transfer and login identities. Use tunnelling software (SSH, VPN or Tor) A big threat to your anonymity when using a VPN service is that of DNS leaks. And the combination of Fail Open and a DNS Leak is the worst. Many Internet Service Providers (ISPs) use DNS redirection to take over a user’s DNS requests for the collection of statistics and returning ads when users access an unknown domain - Some governments use DNS hijacking for censorship, redirecting users to government-authorised sites. Use a free, alternative DNS service .",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "3c7b6c0e8624201d0171f81b61f4d3be",
    "u": "https://pii.tymyrddin.dev/docs/traffic/tunnelling",
    "t": "Tunnelling ",
    "c": "Tunnelling  A tunnel is a mechanism used to ship a foreign protocol across a network that normally wouldn’t support it. Tunnelling enables the encapsulation of a packet from one type of protocol within the datagram of a different protocol. The complete IP packet to be sent from source to destination is encapsulated into another IP packet. This new packet has a legal internet IP address. For example, a VPN can use PPTP to encapsulate IP packets over a public network, such as the Internet. Most tunnelling protocols operate at layer 4, which means they are implemented as a protocol that replaces something like TCP or UDP. This concept can be used for anonymising. Various types of tunnelling are useful for circumventing censorship : SSH and VPN , Mixnets like Tor and I2P Chaining anonymising gateways .",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "99f5746c957869213bc15a5876c8324a",
    "u": "https://pii.tymyrddin.dev/docs/metadata/bleachbit",
    "t": "Clean machine with BleachBit ",
    "c": "Clean machine with BleachBit  With BleachBit you can free cache, delete cookies, clear Internet history, shred temporary files, delete logs, and discard junk you didn’t even know was there. It is available for Linux, Windows, BlackBerry, Email servers and Mac OS X. The version of BleachBit in the repositories of many Linux distributions is often stale, so to use the best and latest version, use the packages from the Download page .",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "28aede7c7ff0cb685833c0c690b5700b",
    "u": "https://pii.tymyrddin.dev/docs/metadata/readme",
    "t": "Introduction ",
    "c": "Introduction  Metadata is data about data. Metadata answers who, what, when, where, why, and how about every facet of the data that is being documented. Photos, and images in general, contain metadata. For photos this includes how large the picture is, colour depth, resolution, the date and time when it was created, the GPS coordinates of the location they were taken at, camera shutter setting details, and possibly even the name of the program used to edit them. Document metadata is information about one or more aspects of a document, spreadsheet, pdf file, that is not always visible to the person creating them, but can be found by the person who receives them next. Comments, track changes, hidden text, mark-ups, properties, attachments and bookmarks are all examples of document metadata. Office documents like pdf or Office automatically add author and organisation information to documents and spreadsheets. Web pages often include metadata in the form of meta tags. Description and keywords meta tags are commonly used to describe the Web page’s content. Most search engines use this data when adding pages to their search index. This type of metadata can be useful, but maybe you do not want to disclose this information on the web, because metadata can be used for other purposes as well: Metadata is collected by corporations for psychological manipulation in persuasion and advertising. Metadata also plays a number of important roles in computer forensics: It can provide corroborating information about the document data itself. It can reveal information that someone tried to hide, delete, or obscure. It can be used to automatically correlate documents from different sources. Metadata is used by hackers doing reconnaissance for an attack And last but not least, it can be used to correlate data in dragnet and targeted surveillance. Techniques for metadata removal  Metadata removal software like the Metadata Anonymisation Toolkit (MAT) identifies and removes the metadata contained within a file. BleachBit cleans a lot more. Use a hex editor for getting in the corners Edit exif metadata in images",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "732e4234ff0e2eb238e1fef805e8c39b",
    "u": "https://pii.tymyrddin.dev/docs/filetransfer/file-sharing-services",
    "t": "Choose file sharing services ",
    "c": "Choose file sharing services  Onionshare allows for sending big files via Tor. When sharing a file, the program creates a Tor Hidden Service — a temporary, anonymous website — hosted on your computer. Give the intended recipient of the file the .onion address for that site, and they can securely and anonymously download it through their Tor Browser. Avaialable for Linux. macOS, and Windows. An Onionshare for iOS and Onionshare for Android are in development. The Onionshare for Android can already be found on the Google Play Store OnionShare Sparkleshare was made to cover certain use cases . Designers at the GNOME Usability Hackfest in London came to the conclusion that they didn’t have a good (Open Source) collaboration tool to share their work. It is not suited for full computer backups and large binary files that change often, like video editing projects. Articles  Google Drive and Dropbox are probably not really private. The problem with their privacy policies and terms of service is not that they are malicious - they’re there to help provide the service, but that they could be misused easily. There is no language that compels either to act in a user’s interest. Alternatives that do use such language exist. A yearly study by Comparitech looks at the number of content removal requests by platform, which countries have the highest rates of content removal per 100,000 internet users, and how things change on a year-by-year basis. The question Comparitech focuses on is “Which government censors the tech giants the most?”",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "472f7f5f40eb3507570b2e3201251bb2",
    "u": "https://pii.tymyrddin.dev/docs/email/hibp",
    "t": "‘;–have i NOT been pwned? ",
    "c": "‘;–have i NOT been pwned?  ‘;–have i been pwned? (HIBP) is a database of several billion email addresses (and, separately, passwords) that have appeared in a publicly known past data breach. The service creates an SHA-1 hash of the submitted email address and passes the first six characters of that to HIBP’s hash range query API. HIBP then returns a range of possible matches, if any, to the six character string, without ever handling the full email address. Check if you have an account that has been compromised in a data breach, and if so, change your password and change it in any other place where you’ve used that password. Better yet, never use a password twice, and consider using a password manager.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "4c156edef7459444a904a7411531e688",
    "u": "https://pii.tymyrddin.dev/docs/browsing/private-browsing",
    "t": "Private browsing ",
    "c": "Private browsing  Privacy mode or “private browsing” or “incognito mode” is a privacy feature in some web browsers to disable browsing history and the web cache. This allows for browsing the internet without storing local data that could be retrieved at a later date, as in, not saving a history of the pages visited on the Internet. Private browsing in Chrome is called Incognito. To open an Incognito window in Chrome, click Settings. From the drop-down menu, click New Incognito Window. For a Private Browsing window in Firefox, click Settings. From the drop-down menu, select New Private Window. Turn Private Browsing on or off on an iPhone, iPad, or iPod touch by opening Safari and tapping Settings, Private, and then Done. When using “private” or “incognito” browsing, your real IP address and location are still being revealed to every w ebsite, ad, and tracker that loads in your browser, and your traffic remains visible to your internet service provider (ISP). ISPs log everything and share the data with many other parties. It is essential to also use a good VPN for basic digital privacy.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "df03cce6ac392d2c18bd5afd750ee43a",
    "u": "https://pii.tymyrddin.dev/docs/metadata/mat",
    "t": "Metadata Anonymisation Toolkit 2 (MAT2) ",
    "c": "Metadata Anonymisation Toolkit 2 (MAT2)  mat2 provides a command line tool, and graphical user interfaces via a service menu for Dolphin, the default file manager of KDE, and an extension for Nautilus, the default file manager of GNOME. This is a tool natively created under Debian-Ubuntu and available as Debian and Ubuntu package . For usage, read the Man page .",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "cfe184bb42ce1f9205125630cf29bdf2",
    "u": "https://pii.tymyrddin.dev/docs/traffic/change-nick",
    "t": "Change nickname ",
    "c": "Change nickname  Wireless access points are wireless devices that will take the network signal from a router and broadcast it wirelessly. An AP and a Wireless Router are two different things but many people simply lump all the wireless devices like that under the term AP, because they are the point at which you access your network. SSID stands for Service Set Identifier (802.11 Nickname) and is the primary name of a WiFi network. This field is a little-known feature of the wireless spec that sends your hostname to the Access Point. Most router manufacturers set default router SSIDs like NETGEAR_XXXX or Linksys_XXXX . Anyone in the area with a packet sniffer can see your “nickname” and know what type of router you are using. Changing the name of a router does not really increase its security, but it does signal security awareness and that hacking may not be that easy. You can also hide the name by turning off the SSID broadcast, but that too is not a significant cybersecurity measure. Nobody will be able to see the SSID if it is hidden, but the traffic on the network can still be tracked. Find SSID  Turn on your Wi-Fi. Windows: Click on the Wi-Fi icon located on the bottom right corner Mac: Click on the Wi-Fi icon located on the upper right corner Android: Go to Settings > Wi-Fi iOS: Go to Settings > Wi-Fi Linux: Depends on desktop and network manager Make sure the router you are connected to is the correct SSID. Mind the evil twin attack, a hack attack in which a hacker sets up a fake Wi-Fi network that looks like a legitimate access point to steal victims’ sensitive details. Change SSID  All routers are different, but in general the route to changing the nickname is something like this: Log in to the router (admin), for example with the default network name and password printed on the case of the router. Find your router’s IP address. Change the SSID and password to, for example “FBI Surveillance Van”. Update the connection for all devices.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "97f7a85d3b3a8f211571ec206b2baab9",
    "u": "https://pii.tymyrddin.dev/docs/traffic/renew-lease",
    "t": "Renew IP lease ",
    "c": "Renew IP lease  A DHCP client can on occasion send information in DHCP requests: hostname, MAC address, operating system, and DHCP version. All operating systems provide their most recent IP address to the DHCP server. If you change your MAC address to minimise risk, best to also renew the IP leases on the router. Workstations and PC’s  Linux: Renew IP lease macOS: Renew IP lease Windows: Renew IP lease",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "68331e23fc207f7dbe60112dc94f60bf",
    "u": "https://pii.tymyrddin.dev/docs/traffic/vpn-fail-open",
    "t": "VPN Fail open ",
    "c": "VPN Fail open  If you simply add a VPN using common instructions, it generally “fails open”. That means, if the VPN breaks down, because the connection is interrupted, traffic will be sent without the VPN. It is much safer when it “fails closed”, meaning that when the VPN connection breaks down, the whole internet connection must be down as long as the VPN connection is not restored. If your chosen VPN does not include being able to set a kill switch, you can use a firewall as a VPN fail-safe mechanism, or routes. Workstations and PC’s  Linux: Use a firewall as a VPN fail-safe mechanism macOS: Use a firewall as a VPN fail-safe mechanism Windows: Make a VPN killswitch using routes",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "d52e02338fb93f9cd238a8f9d5079ea3",
    "u": "https://pii.tymyrddin.dev/docs/traffic/dns-leaks",
    "t": "DNS leaks ",
    "c": "DNS leaks  When you don’t set up DNS servers on your computer or router, your DNS queries will run on your ISP’s DNS servers. Without VPN (or VPN Fails Open ), DNS requests are most likely sent unencrypted, which can lead to many different types of common DNS attacks. Domain hijacking (Redirection) DNS flood attack (a type of DDoS attack) DNS spoofing or DNS cache poisoning DNS hijacking (malware infection on a local device to hijack DNS to redirect traffic to a phishing site) And any man in the middle of your traffic can see your online behaviour and the websites you visit. Your ISP’s DNS servers see every search you make in your browser. Using your ISP’s DNS servers as default DNS servers doesn’t do anything for security or privacy. Workstations and PC’s  Linux: Use alternative DNS servers Windows:Use alternative DNS servers macOS: Use alternative DNS servers",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "304bde013c67e4375ccbd3db717afb15",
    "u": "https://pii.tymyrddin.dev/docs/webapplication/readme",
    "t": "Introduction ",
    "c": "Introduction  Unauthorised access to our data can occur due to a web application not properly protecting data. A lack of quality encryption and improper key generation is often cause. Luckily, this type of vulnerability is relatively difficult to exploit when we have our machines locked down. If you are running your own website or blog: Protect websites with the HTTPS (SSL/TLS) protocol UnFloC your site Make your site GDPR compliant Secure file uploads from users",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "f6f5193558451808addcd0d0a0f8030b",
    "u": "https://pii.tymyrddin.dev/docs/filetransfer/integrity-downloads",
    "t": "Checking integrity of downloads (Linux) ",
    "c": "Checking integrity of downloads (Linux)  When downloading an ISO image of, for example, installing or upgrading packages or applications, or downloading software, you can verify the files have downloaded correctly and securely by using checksums. Checksums ensure the integrity of data portions for data transmission or storage. Checksums is a simple error-detection scheme in which each transmitted message is accompanied by a numerical value based on the number of set bits in the message. The receiving station then applies the same formula to the message and checks to make sure the accompanying numerical value is the same. If not, the receiver can assume that the message has been garbled (or was altered). Workstations and PC’s  Linux: Check integrity of downloads Windows: Check integrity of downloads AMFI: checking file integrity on your Mac",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "628a182b5da41a80c4e972ceadce9b4c",
    "u": "https://pii.tymyrddin.dev/docs/traffic/tor",
    "t": "Using Tor ",
    "c": "Using Tor  Onion routing networks like the Tor network are designed to resist a local adversary, one that can only see a subset of the network and the traffic on it. In a (sort of) mixnet like that, each node will only know the relay path in which it is involved, but not the whole path from the source to destination. If being discovered does not have serious consequences for you, we recommend using the Tor Browser Bundle . Warnings taken seriously  If a government makes their own national internet, or routes traffic through specific servers to use deep packet inspection (DPI), running Tor may not provide security if the government is able to see the entire path. Sometimes the Tor network is censored, and clients can’t connect to it. An increasing number of censoring countries are using Deep Packet Inspection (DPI) to classify Internet traffic flows by protocol. While Tor uses bridge relays to get around a censor that blocks by IP address, the censor can use DPI to recognize and filter Tor traffic flows even when they connect to unexpected IP addresses. With pluggable transports, censorship against Tor can be bypassed. Not only that. If an attacker can see your traffic, and can see the website you’re visiting, even with a path outside the adversary’s control - they will still be able to correlate the traffic and learn you are visiting the website. If the same connection (the same set of relays) were to be used for a longer period of time a Tor connection could be vulnerable to statistical analysis, which is why the client software changes the entry node every ten minutes. Blocking Tor  Even the introduction of Bridge nodes did not stop certain organizations and governments from trying to detect and block the usage of Tor. The usual suspects for attempts at blocking Tor are: Blocking of the publicly available list of Tor relays. Creating Application Filter Policies in firewalls where only certain approved networks (LAN Networks) will be able to use specified proxy services. Creating an SSL Decryption policy in firewalls. IDS/IPS can be used to decrypt SSL certificates and detect traffic related to websites hosted on Tor. Tor browsing involves two types of ports, ORPort and DirPort. ORPorts (port 80 and 443) are used to make connections and transmissions and DirPorts (port 9001 and 9003) are used to fetch updates from the directory servers. Firewalls and IDS filters can be configured to monitor any traffic going towards or coming from the ports 9001 and 9003. Pluggable transports  Pluggable transports are tools that Tor can use to disguise the traffic it sends out. This can be useful in situations where an Internet Service Provider or other authority is actively blocking connections to the Tor network. obfs3 makes Tor traffic look random, so that it does not look like Tor or any other protocol. While still included by default, it is recommended to use obfs4 instead, as it has several security improvements over obfs3. obfs4 makes Tor traffic look random like obfs3 , and also prevents censors from finding bridges by Internet scanning. obfs4 bridges are less likely to be blocked than obfs3 bridges. FTE (format-transforming encryption) disguises Tor traffic as ordinary web (HTTP) traffic. meek transports all make it look like you are browsing a major web site instead of using Tor. meek-amazon makes it look like you are using Amazon Web Services; meek-azure makes it look like you are using a Microsoft web site; and meek-google makes it look like you are using Google search. Snowflake is an improvement upon Flashproxy. It sends your traffic through WebRTC, a peer-to-peer protocol with built-in NAT punching. Workstations and PC’s  Linux: Use a Tor proxy macOS: Use a Tor proxy Windows: Use a Tor proxy Phones  Android: Use a Tor proxy iOS: Use a Tor proxy",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "0545d1bf27f3a3ba252103d15b132711",
    "u": "https://pii.tymyrddin.dev/docs/metadata/hexeditors",
    "t": "Remove metadata with hex editors ",
    "c": "Remove metadata with hex editors  The hexadecimal notation is almost universally used in computing - and not without a reason. There are sixteen hex digits - 0 to 9, and A to F (which correspond to decimal values 10 to 15), and each hex digit represents exactly four bits. Exactly two hex digits represent a byte, which can have a value from 00 to FF. A hex byte is the only kind of object a computer handles, and hex bytes are used to represent anything. For example, a hex byte 50 may represent the capital letter P, the processor command push eax, the decimal number 80, a colour component with 50% brightness, or whatever else lives in the digital world. And that means we have editors, hex editors, that can be used to view and change files, all files, on a very low level. As in, they can be used to remove metadata from any and all files. Usage in general  backup the file before using a hex editor on it. switch to ASCII mode, turn off “read only” mode, and start searching through the file. For example, when scrubbing pdf’s from creation and modification information look through the entire file for “created” (metadata appears in the PDF file more than once). If and when you find metadata, change to fake data or delete. Then repeat your search again for the terms “create”, “creation”, “modified”, and “modify”, and similarly either replace or delete the dates, once again being sure to repeat each search so that any potential multiple instances of the field can be located and modified or blanked out. Workstations and PC’s  Linux: Remove metadata with hex editors Windows: Remove metadata with hex editors macOS: Remove metadata with hex editors",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "71b0dc0e23c5595c104679fd415202f5",
    "u": "https://pii.tymyrddin.dev/docs/browsing/user-agent",
    "t": "Switch your user agent ",
    "c": "Switch your user agent  You can add your own user-agents, and even mimic being a webspider and switch between them. For a list of convincing user-agents see this searchable database of user-agents as used by browsers, search-engines spiders and crawlers, web-directories, download managers, link checkers, proxy servers, web filtering tools, harvesters, spambots, and badbots. Because LibreWolf and Brave browser are resp. based on Firefox and Chrome, these may also work in those (still have to try that). Reuseful user-agent switcher plugins exist to make life easier (not available for all versions though): Chromium user agent switcher Firefox user agent string switcher",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "c77deaad4a0b92739b8e2bd9039c0c19",
    "u": "https://pii.tymyrddin.dev/docs/avoiding-surveillance",
    "t": "Avoiding surveillance ",
    "c": "Avoiding surveillance  The Snowden leaks revealed a massive surveillance program including interception of email and other internet communications and phone call tapping. Upstream collection, Hemisphere and XKeyScore by way of wealthycluster2 gobble up our metadata, and with interconnected systems such as by ICReach that data can be shared and associated with other data. There are dozens of clever analyses that can be performed with such linked databases. I’m sure that is what they’re doing right now. If I can think of it, so did they. And it is not just the US spying on its citizens and its “adversaries”. Every citizen on this planet is subject to dragnet surveillance. This includes data that does not, by itself, identify individuals, but sits in various databases until analysts do a search for a particular name. What tools to use?  Just a getting started … As with anonymising traffic, it depends on where you are, what the state adversary makes available in terms of resources and what the consequences of discovery in your country may be. Assets Threat(s) Mitigation(s) Communications Nearly all states are copying and searching the communications (for example email addresses) and content of virtually every communication that comes into or goes out of the country, without a warrant. Use encryption. Intelligence agencies target encrypted traffic, but any encryption is still better than sending traffic in the clear. Encryption software Be suspicious of commercial encryption software, especially from large vendors: The secret agreements between intelligence agencies and technology companies extends to those developing security and encryption software.(For avoiding implicitly backdoored algorithms: Try to use public-domain encryption that has to be compatible with other implementations as much as possible: Do not use proprietary software; Avoid elliptic-curve systems.) Assume that every commercial application has a backdoor and that ghost protocols exist. IP address Packet headers identify the IP addresses of sender(s) and recipient(s) and the packet routes can rather easily be tracked. Use tunnelling ( VPN or SSH or Tor ) and when doing so never ever post any personal data. Communications can be encrypted so that an observer cannot learn the content of these transmissions easily (it will cost), but this still reveals the fact that two parties are communicating MAC address MAC addresses can be and often are used by networking equipment to track users. This means proxy hopping on a network that has already authenticated your hardware is utterly useless. Regularly change mac address Video metadata There are two sources in which video metadata is derived: operational gathered metadata - information about the content produced, such as the type of equipment, software, date, and location; and human-authored metadata Do not add human-authored data and remove operational video and camera data Telecommunications metadata Information on the times, origins and destinations of phone calls, electronic messages, instant messages and other modes of telecommunication Digital photo metadata Metadata may be written into a digital photo file that will identify who owns it, copyright and contact information, what brand or model of camera created the file, along with exposure information (shutter speed, f-stop, etc.) and descriptive information, such as keywords about the photo, making the file or image searchable on a computer and/or the Internet. Do not add human-authored data and remove operational video and camera data Document metadata Metadata may be written into documents that will identify who owns it, copyright and contact information, and descriptive information, such as keywords, making the file searchable on a computer and/or the Internet. Do not add human-authored data and remove operational document data username(s) A user often has a user account and is identified to a system by a username, login name, screen name, nickname, nick or handle Regularly change user names; have a few pseudonyms (that you only use on separate (virtual) machines) Digital identity Digital identity based on dynamic entity relationships captured from behavioural history across multiple websites and mobile apps can verify and authenticate an identity with up to 95 percent accuracy. Use tunnelling (VPN or SSH or Tor) and when doing so never ever post any personal data.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "112fcd5adaaed133e4ce7fdf9a004308",
    "u": "https://green.tymyrddin.dev/",
    "t": "Understandables ",
    "c": "Understandables  A systems approach is not often considered. Tunnel visions (on profit) rule. “He’d been wrong, there was a light at the end of the tunnel, and it was a flamethrower.” –Terry Pratchett The green team focuses on the larger environment, both technical and human, on documenting what is happening and understanding the unseen logic of the forest, causes and effects, bottom-up and top-down, with intent of creating human-readable information for improving communication, lowering thresholds for participation, and providing people with well-understood choices. The threat landscape for people in the public and private sector has changed enormously over the past decade. Physical threats have decreased (some), while digital security threats have increased, and can be a prelude to a physical attack. De-anonymisation threat model Introduction Adversaries Assets Attack vectors Attacks Assistive technologies Threats Impacts L-Space Defendable internet The Great Offshore Arms Trade Litigation Monitor Pervasive surveillance The Big Mess  Centering Society in Big Tech reform Richard Hill Silicon Valley’s Digital Defence industry Roberto J. González Digital capitalism is a mine not a cloud Maximilian Jung What Artificial Intelligence is hiding Karina Pedace, Tomás Balmaceda, Tobías J. Schleider",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "45b7b20346281850bf5946d2719cfbb0",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/attacks",
    "t": "Attacks ",
    "c": "Attacks  Inference attacks  The majority of attacks are inference attacks. The simplest inference attacks are derived from early code breaking, where codes were created by swapping around individual letters, or by substituting glyphs for the alphabetic characters. Once the relative frequency of the various letters in a character substitution language is found, messages using the code can be easily cracked. In a similar fashion, a pseudonymised database may have the City field disguised. Cities have varying populations, and if the population in the database conforms to a known population, those cities can be identified, and this tentative identification can be firmed up by looking at the distribution of addresses within the city, or by other auxiliary information (also called background information) on individual cities. A seemingly somewhat harmless example. But not when combined with other information. The easiest way of revealing individual data is to combine two or more databases. Once the individual is identified, an inference attack can then use the GPS location and movement data of a user, possibly with some auxiliary information, to deduce other personal data such as their home and place of work, interests and social network, and even home in on religion, health condition or business confidential data coming from the user’s employer. Data about people and their activities is passed around for research purposes. Advances in medicine can be made by finding patterns in existing patient and biomedical data. When such data is pseudonymised and made public or shared, it can unintentionally reveal sensitive data about an individual, such as their medical condition, or how much they were charged for treatment. Every inference attack is slightly different because it depends on the data and relies on drilling down to a unique combination of characteristics. Available information such as friendships or group relationships in social media datasets can be used to infer sensitive properties that reveal hidden values or behaviours. Some techniques use algorithms to infer values or behaviours from customers’ transactions using auxiliary information with temporal changes of recommender systems. Bayesian inference can be used to gain knowledge about communication patterns and profile information of users. Naive suppression such as pseudonymising datasets does not prevent privacy breaches. The more useful a record is for scientific or marketing research, the more vulnerable it is to inference attack. Linkage attacks  Linkage attacks are another common form of de-anonymisation attacks. In this attack, adversaries collect and combine auxiliary information about a certain individual from multiple data sources with their anonymised records in a dataset to form a whole picture about their target, which is often an individual’s personally identifiable information. For example, the adversary downloads a sanitised production network dataset that was released in the past. The dataset contains captured traces in which all MAC addresses have been sanitised and are thus unknown to the adversary. The adversary observes a sequence of AP association records of a target victim for a short period of time, to infer the MAC address from the released dataset that is associated with the victim. The attacker obtains broader knowledge of the victim’s mobility history from the released dataset, which leads to an infringement on the privacy of the user. The possibilities are endless: A health care provider shares anonymised data with for example researchers from a pharmaceutical or health assurance company about medical conditions. The export contains “Gender,” “Postal code,” “Date of birth,” and “Medical condition description.” An adversary can easily use an open data (public made) voter list that contains “Name,” “Gender,” “Postal code,” and “Date of birth” to cross-reference the patients. Netflix published data about movie rankings for 500,000 customers, and researchers showed they could de-anonymise the data using a few additional inputs from IMDb. AOL published search data for 650,000 users, thinking it was enough to anonymise their name using a unique ID. Unfortunately, most users often query their own name. Someone with access to an anonymous dataset of telephone records, might partially de-anonymise it by correlating it with a telephone order database of a catalogue merchant. Amazon online book reviews can be key to partially de-anonymising a database of credit card purchases, or a larger database of anonymous book reviews. Search engine databases with logs of internet searches, could easily be used de-anonymise a database of internet purchases, or zoom in on searches of medical terms to de-anonymise a public health database. And vice versa, detailed customer and purchase information datasets can be used to partially de-anonymise any released large anonymised search engine data set. A data broker holding databases of several companies might be able to de-anonymise most of the records in those databases. The most common approach to mitigate linkage or correlation attacks is to anonymise data before exporting by removing personally identifiable information (PII). This does not suffice. At all. A better approach to protect against correlation attacks is to simply not share. It was proposed, that if data is shared — to create layers of abstraction or generalisation by redacting parts of the data. If only microdata that contain spatial information in an aggregated form are released, the choice of applicable techniques for analysis becomes drastically reduced because distance calculations that are based on aggregated data become difficult and imprecise, especially for entities that are spatially close to each other. This then leads to the conclusion that to continue to do research on large datasets with privacy protection for the owners of the data, it is necessary to investigate the extent to which additionally published (approximate) inter-record distances influence the risk of identity disclosure and how a possible non-acceptable increase of this risk can be prevented. Many organizations are not aware of the linkage risk involving quasi identifiers, and while they may de-identify direct identifiers in a dataset, they often do not think of de-identifying the quasi-identifiers in the dataset. Advanced anonymisation techniques of target datasets are needed. Structural attacks  This type of attack typically exploits social network structures by using graph matching on network datasets. Many people have accounts through various social networks such as Facebook, Twitter, etc. With structure-based attacks an individual’s network context can be used to identify them even if other identifying information is removed. Even when equipped with advanced anonymisation techniques, the privacy of structural data can suffer from de-anonymisation attacks assuming that adversaries have access to rich auxiliary information from other channels. Abstractly there is a graph G from which two graphs Gt (for “target”) and Ga (for “auxiliary”) are derived via some stochastic process. There is thus a natural notion of (partial) correspondence between the nodes of Gt and Ga; the goal of de-anonymization is to recover this correspondence. The stochastic process involved could be as simple as the deletion of random edges. At the other extreme, if we’re considering two entirely different online social networks, say Facebook and LinkedIn, then \\( G\\) is the underlying social graph of human relationships, and Gt and Ga are generated according to the processes by which users join online social networks, which has no simple algorithmic description. The privacy-sensitive data closely related to individual behaviour usually contain rich graph structural characteristics. For example, social network data can be modelled as graphs and mobility traces (WiFi contacts, Instant Message contacts) can also be modelled as...",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "17b0d3d194699e8962e0ac984839d4f5",
    "u": "https://green.tymyrddin.dev/docs/l-space/defendableinternet",
    "t": "Defendable internet ",
    "c": "Defendable internet  Keynote Blackhat 2017: Why We are Not Building a Defendable Internet  In IT security, offensive problems are technical - but most defensive problems are political and organisational. Attackers have the luxury to focus only on the technical aspects of their work, while defenders have to navigate complex political and regulatory environments. In a previous talk named Rearchitecting a defendable internet , keynote speaker Thomas Dullien (aka Halvar Flake) discussed what technical measures would yield defendable devices - and intentionally omitted the political and economics side. This talk explored the economics and incentive structures in IT security: Who is incentivized by who to do what - and how these incentives fail to produce the security level we desire. The talk discusses different players in IT security: CISOs, security product vendors, computer manufacturers, cyber insurances - and examine their economic incentive structures, their interplay, and reasons for failure. The talk also discusses an alternate reality where things work smoothly, and examine the differences to our current (which was 2017) reality. Keynote BlackHat 2022: Our Kryptonite: A Defendable Internet  This talk by Daniel Cuthbert follows up on that. Five years in Internet years is a long time, so what has changed for the better or worse? Does good security mean a lock-in approach or are we actually capable of building an open, transparent, and yet secure internet for all to enjoy? Can we stop the cycle of building tools to fix the tools that aren’t secure enough? Thank you both for mentioning the unmentionables. I wish to argue that it is a systematic problem, not a conglomeration or loose confederation of separate disciplines and individual choices. If that is true, merely improving the parts of a system will not improve the whole. Every problem is part of “The Mess”, and the “Big Security Mess” includes all the messes that besiege globalising complex capital, and the incentives it instills.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "c4877b22d9b2b1cecb154f319f0fa8ac",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/assistive",
    "t": "Assistive technologies ",
    "c": "Assistive technologies  Data science skills that make adversaries highly effective at de-anonymisation are matching features, prediction and inference, which all require computational, statistical and probabilistic skills. Behavioural analysis  The intention of behavioural targeting is to track users over time and build profiles of their interests, characteristics, such as age and gender, and shopping activities. Online advertisements use behavioural targeting to display advertisements that reflect users’ interests. Developing an understanding of behaviour is not a new idea, and it already has uses in a variety of related contexts. For example, behavioural monitoring is a long-standing technique in the context of Intrusion Detection Systems (IDS), law enforcement agents use profiling all the time (and when based on racial profiling interferes with the system of criminal justice), and so-called profilers, specially trained agents, look at a crime scene, autopsy data, victims, and likely pre-crime and post-crime behaviours of a serial killer to make psychological assessments (that are considered by some to be ‘worse than useless’). Based on mining data, including inference and linkage attacks in which data is associated from one source with data and online behaviour from other sources, the profiling practice is being used in surveillance systems, to tailor our digital experiences for us, by for example marketers to try to get us to consume more, and by politicians to influence elections. Behavioural analytics requires and includes: Available data sets, possibly bought from data brokers or on a black market. Real-time capture of vast volumes of raw event data across all relevant digital devices and applications used during on-line sessions. Automatic aggregation of raw event data into relevant data sets for rapid access, filtering and analysis. Ability to query data in a number of ways, enabling users of the analytics system to ask questions. A library of built-in analysis functions such as cohort, path and funnel analysis. A visualization component. Cohort analysis breaks all users into related groups (sharing common characteristics or experiences within a defined time-span) for analysis in order to understand if a group is doing what it’s supposed to be doing (or what a company/organisation/agency/government wants those individuals to do) on a regular basis. For example, in an IoT application, are a group of machines – say for example edge devices such as smart thermostats – streaming the necessary data? In an e-commerce site like Amazon, are customers in a certain demographic completing a purchase? What are the desired actions or results? And what are the paths that can get the actor (user) to take those? These questions belong to the domain of path analysis. An individual may take any number of steps before reaching a desired state. A path analysis analyses all the points and actions that individuals take at each point. Streamlined paths to a desired state can be identified and points in a path where a barrier exists that keeps individuals from moving forward. Path analysis gives insight into why people are doing what they are doing, and at what point they are doing it. Funnel analytics are used to identify users’ progress through defined steps towards a specific goal. It shows the narrowing of participants as they move along a sequence to an end state. For example, Amazon offers a portfolio of products, then a specific product page, online reviews about the product, a shopping cart button, fields for shipping options and credit-card entry, and finally a purchase button. With funnel analysis the rate at which individuals follow the steps of a sequence to produce an end state can be analysed. In other words, how many people dropped out of the funnel versus those that actually bought the product? Who were they? Funnel analysis can be combined with cohort analysis: Did a specific group of people or machines drop out at one stage of the sequence? Content analysis  Content analysis is a method for analysing a user’s content (in online social networks) for providing information about its structure or some attributes. Content analysis is a research tool used to determine the presence of certain words or concepts within texts or sets of texts. Researchers quantify and analyze the presence, meanings and relationships of such words and concepts, then make inferences about the messages within the texts, the writer(s), the audience, and even the culture and time of which these are a part. Texts can be defined broadly as books, book chapters, essays, interviews, discussions, newspaper headlines and articles, historical documents, speeches, conversations, advertising, theater, informal conversation, or really any occurrence of communicative language. Because it can be applied to examine any piece of writing or occurrence of recorded communication, content analysis is used in many fields, from marketing and media studies, to literature and rhetoric, ethnography and cultural studies, gender and age issues, sociology and political science, psychology and cognitive science, and many other fields of inquiry. Link prediction  Link prediction is a method that an adversary can use to bridge between auxiliary information and a target dataset if they are from different sources and have little in common for matching. Predictive analysis  Predictive analytics is the practice of extracting information from existing current and historical data sets in order to determine patterns and predict future outcomes and trends by statistical techniques from modelling, machine learning, and data mining. Predictive analytics does not tell you what will happen in the future. Clustering  Cluster analysis can be used when there are a lot of content nodes that are to be divided into different content clusters, and no idea how to create them. Rather than defining groups before looking at the data, clustering allows for finding and analysing groups that have formed “organically” (based on similarity). Applications for cluster analysis include gene sequence analysis, market research, and object recognition. When choosing a clustering algorithm, consider whether the algorithm scales to the dataset. Not all clustering algorithms scale efficiently. Many clustering algorithms work by computing the similarity between all pairs of examples. This means runtime increases as the square of the number of examples. Centroid-based clustering organises the data into non-hierarchical clusters. K-means is the most widely-used centroid-based clustering algorithm. Centroid-based algorithms are efficient but sensitive to initial conditions and outliers. Connectivity-based (alias hierarchical) algorithms create a tree of clusters. An advantage is that any number of clusters can be chosen by cutting the tree at the right level. Density-based algorithms connect areas of high example density into clusters, allowing for arbitrary-shaped distributions. These algorithms have difficulty with data of varying densities and high dimensions. And by design, these algorithms do not assign outliers to clusters. With the OPTICS algorithm one can view intrinsic clustering structure that could otherwise be identified only in a process of repeated clustering with different parameter settings. Probabilistic (alias distribution-based) algorithms assume data is composed of distributions. As distance from the distribution’s centre increases, the probability that a point belongs to the distribution decreases. Do not use if distribution is not known. Dimensionality reduction reduces the number of features under consideration, where each feature is a dimension that partly represents the objects. With too many features, the data matrices become sparse and analysis suffers from the curse of dimensionality (loss of statistical significance). Plus that it is easier to process smaller data sets. This is achieved by feature selection or...",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "2d07e5c183fb2cef8651311ce07c239d",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/readme",
    "t": "Introduction ",
    "c": "Introduction  What?  Using attacker-based threat modelling with a quite non-trivial adversary, namely an entire ecosystem of players and an often forgotten target, the individual citizen. Why?  De-anonymisation is a strategy in data mining in which anonymous data is cross-referenced with other sources of data to re-identify the anonymous data source, often used by those that do not have users’ best interest in mind. De-anonymisation also works to further help improve anonymisation techniques and reduce privacy breach by probing the potential drawbacks of anonymisation techniques. How?  Adversaries Assets Attack vectors Attacks Threats Assistive technologies Impacts",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "2d6fdbedca5931fe84afe427f012fc04",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/assets",
    "t": "Assets ",
    "c": "Assets  Data releases  Assuming three main contexts of data release, in which each presents a different relationship, therefore a different level of trust between the data provider and data recipient, and a different level of control and risk. Internal secondary research is about data re-use. For example, clinical trial sponsors store and maintain vast amounts of data collected during clinical studies. The cumulative information may be invaluable for identifying patterns which are not the focus of the original trials. Sponsors are required to obtain consent for such use of patients’ data, which they may claim is not possible or entirely impractical (due to the enormous amounts of “data subjects”). The alternative is to anonymise the data such that it is no longer considered personal information. In this scenario access to data is controlled by mechanisms much like those used in primary analysis. While the requirement to de-identify the data needs to be observed, the risk of re-identification attempts is considered minimal. External secondary research is about sharing data with external researchers, under strict contracts, through secure means will supposedly ensure that the process is safe and the risks involved very low. The anonymisation process will have already considered the probability of de-anonymisation attempts – rogue employee, data breach, etc. - and taken it into account in finding and applying adequate level of anonymisation. Introducing contractual controls and limitations on how the data is accessed, used and disposed of, is thought to significantly limit the motivation of the data recipient to attempt de-anonymisation and illicit use of data. When data is released to the public domain, there is no control over how it will be used and an adversary wanting to access the data can do so with little effort. The data industry is confronted with finding it hard to assess motivations of adversaries and the level of knowledge and tools they may possess and use and that may land its data guardians in protective states of mind that may lead to significant loss of data usability. The industry therefore finds it crucial to identify plausible adversaries relevant to a context and contents of the data release which they think may result in less de-anonymisation and greater data utility retention. Auxiliary information  Auxiliary information is the information gained as background knowledge by the adversary. It is any data that might be combined with other data(sets) to give meaningful information. It is usually gathered from real world information (but not always, this too has expanded): with the usual information gathering techniques for example from work environments, such as personal information of/from colleagues, from dumpster diving, and from any public information, such as a voter list, petition sites, forum comments, or reviews in websites, to name but a few. from neighbourhood data collected in open data sets. from another dataset that was either bought at a black market or gained from a merger or buying up a small data company. and in some cases even from the target dataset. Target dataset  The target dataset is a set of anonymous data (also known as de-identified data). The most common methods for de-identification (anonymisation) are by removing personal identifiable information (PII) such as ID and phone numbers, and using sophisticated anonymisation schemes such as k-anonymity, l-diversity, and t-closeness. The new kid on the block is differential privacy. Personal data, also known as personal information, personally identifying information (PII), or sensitive personal information (SPI), is any information relating to an identifiable person. Personally identifying information is a legal concept, not a technical concept, and is not used in the same way in all jurisdictions. Plus that with current re-identification attacks, the absence of PII data does not mean that the remaining data does not identify individuals. k-anonymity  A dataset provides k-anonymity protection if the information for each individual in the dataset cannot be distinguished from at least k − 1 individuals whose information also appears in the dataset. k-anonymity and its variants can protect the privacy of structural data to some extent, but are susceptible to structure-based de-anonymisation attacks due to the limitations of the schemes (they are syntactic properties based) and the rich amount of auxiliary information available to adversaries. Differential privacy  With static anonymisation, an analyst must decide ahead of time which fields contain sensitive data, and then either remove or alter these fields before running the analysis, which reduces the quality of the data set. Plus, the analyst must also consider any auxiliary information a potential hacker might have that could lead to re-identification of the sensitive fields. With dynamic anonymisation, also called interactive anonymisation, data is anonymised on a query-by-query basis, without destroying the quality of the data set. In differential privacy a query should not reveal whether any one person is present in a dataset or what their data are. Imagine two otherwise identical datasets, one with an individual’s information in it, and one without it. The probability that a query will produce a given result is nearly the same whether conducted on the first or second dataset. If an individual’s data does not affect the outcome of a query, then it might be okay to give this information because it is unlikely that the information would be tied back to the individual. And, if an analysis on a dataset finds a correlation between two characteristics, then interpretation of and assigning significance to the correlation, might have an effect on an individual with that characteristic, regardless of whether the individual’s dataset was included in the study. In short, differential privacy supposedly offers the benefits of data research without sacrificing privacy and supports “Legitimate Interest” processing by overcoming shortcomings of “static” data protection techniques that do not adequately protect data subjects against unauthorized re-identification when data is combined from multiple sources or used for various purposes. Jane Bambauer, Krishnamurty Muralidhar, and Rathindra Sarathy have shown that by itself differential privacy will usually produce either wrong research results or useless privacy protections. Differential privacy was developed to protect the privacy of interactive data release. It cannot defend against structural data de-anonymisation attacks which can breach the privacy of non-interactive data releases.",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "943e65c665248427184a9c1111bf8e2d",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/threats",
    "t": "Threats ",
    "c": "Threats  Identity disclosure  Identity disclosure refers to deanonymising a user identity. Content disclosure  Content disclosure refers to revealing any anonymised sensitive personal data – including “special categories” of data relating to racial or ethnic origin, political opinion, sexuality, religious or philosophical beliefs, trade union membership, health or genetic data, or criminal convictions, and other sensitive data such as identity documents or financial data. Link disclosure  Link disclosure refers to deanonymising relationships between users, which can eventually lead to identity disclosure. New form of consent  The Internet is not moral or immoral, it reflects what we ask from it. Marketers will pay more for consumers than consumers will pay for content. People avoid paywalls, and do not sufficiently protect themselves from cookies and trackers. Apparently, having our personal data used for being advertised to is our preferred method of payment for internet services. We seem to have a new standard for consent. When we go on a website, when we visit it, we are giving the adversaries permission to take any information they want?",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "03d4166f77b382dd5db668ab16f5324b",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/adversaries",
    "t": "Adversaries ",
    "c": "Adversaries  Data scientists  Being hired or paid by data analysis agencies, politicians and people in other industries, data scientists and analysts are considered to be among the most likely potential adversaries that have the motivation to attempt a re-identification (identity disclosure, link disclosure and content disclosure), and have the necessary knowledge and tools. Data scientists are data wranglers. They take data points (unstructured and structured) and use math, statistics and programming to clean, manage and organise data. Then they apply industry knowledge, contextual understanding, a critical attitude towards existing assumptions – to uncover hidden solutions. There are a few data scientists working for universities and other institutes, answering some very interesting questions and/or working to solve some societal or medical problems (The road to hell may paved with good intentions), but most work for businesses trying to find solutions to business challenges. One might say, these find opportunities for businesses to make more money. A whole new industry. Data science and data mining are dissimilar terms, but when it comes to data they often go hand in hand: Data mining is about finding trends in data sets, and using these trends to identify future patterns. It often involves analysing vast amounts of structured data. It is a technique mostly used by businesses to make use of data to find new trends. If you know how to navigate data and have a bit of statistical knowledge, you can do it yourself. Data science studies everything from big (unstructured) data analytics, data mining, predictive modelling, data visualisation, mathematics, and statistics. It is a field of scientific study that aims to build data-centric products for organisations. It finds application in social analysis, and in building predictive models and unearthing new facts in various domains. To do it you need extensive knowledge of machine learning, programming, the domain it is applied to, and often also includes data mining. Advertising eco-systems  Programmatic markets are considered to be among the most likely potential adversaries to broker re-identified data for its customers to place ads on people’s screens. Main motivation is financial gain. Predators seek to minimise spent energy in their hunt for prey. The human hunt for money also tends to take the easiest, opportunistic path. Click-fraud created a full-blown ecosystem of adTech that aggressively monitored users and shoved ads into their face, and fraud-bots that figured out how to get past the countermeasures. Note that it was considered fraud when a bot tricked an advertiser into thinking an ad had been seen, but it was considered totally legitimate for an advertiser to trick users into seeing an ad. Advertisers/marketers want to advertise a product or service to sell it. Publishers own one or several websites/social media and display advertisements for payment. Data brokers collect information from users and sell user impressions (profiles) to advertisers. The rise of data-driven ad techniques has accelerated the evolution of the advertising eco-systems. Brands in-sourced ad operations and agencies became data brokers with a different, more hands-on and data-rich partnership approach than was seen in the past. Programmatic refers to the automation of buying and trafficking processes for audience targeted ads. It excludes direct publisher and ad network contracts specified by standard insertion orders, but it includes various hybrid models in which direct buys are supported by automated processes, going under the general heading of “programmatic direct”, referring to the application of software to automate and optimise the placement of ads sold directly to advertisers by publishers at a human-negotiated price. The programmatic industry grows incredibly fast, and is a complex ecosystem of complementary and competitive product category niches: A Demand-Side Platform (DSP) is a technology that advertisers use to buy ad impressions in an automated way. DSPs allow advertisers to bid on inventory from a variety of media owners/publishers. Supply-Side Platforms (SSP’s) use similar technology to that of a DSP except that it is used by media owners to manage their ad inventory and sell impressions programmatically. SSPs allow media owners to connect their inventory to multiple ad exchanges. Service providers: Creative and media agencies and trading desks who specialize in creating advertising and buying and managing the media placement. Media and data providers: Data providers and the software providers for the ecosystem that manage the ad sales on behalf of publishers (SSP), programmatic ad buying (DSP), and data from multiple sources that is made available to marketers to build segments and targets (DMPs). Marketplaces: Ad exchanges for buying and selling digital media, ad networks that aggregate inventory, and data brokers/exchanges that buy and sell consumer data that can be associated with ad media through an identifier such as a cookie ID. Once a media owner/publisher sells an ad impression, an ad server traffics the ad itself, putting it in front of the target consumer whose impression the advertiser purchased. Consumers are the people being grazed on via impressions. Every time we go to an e-commerce site or a retail store, it is considered track-able commercial behaviour. Even when there are no ads, the tracking is there. Data brokers  Data brokers collect, analyse, combine, and package some of our most sensitive personal information and sell it as a commodity to each other, to advertisers, even to those same public authorities, often without our direct knowledge, let alone our consent. Brokers are considered to be among the most likely potential adversaries that have the motivation to attempt a re-identification (identity disclosure, link disclosure and content disclosure), and have the necessary tools. Main motivation is financial gain. Where there is money being made, there is a market, and there are middlemen brokering data, of which many do not even consider themselves a data broker. While this industry has been around for decades, most people have never heard of data brokers. Thanks to advances in data science and its role in enabling the current internet marketing and advertising and advertising eco-systems, it has grown into a multibillion dollar global industry that operates in the shadows with virtually no oversight. Some data broker products are beneficial or harmless, others are a threat to privacy. Credit bureaus have played and still play a critical data brokerage role in mediating access to financial data. They begun building databases in the mid 20th century, to catalogue us and our habits for marketing, fraud detection or credit scoring purposes. They have adapted to be able to ingest and process the streams of information we make available about ourselves today. Police in both the United States and Europe purchase information and assistance to profile people based on personal data. Political parties are targeting their digital outreach based on details of individual behaviour. Employers routinely turn to data brokers to purchase reports regarding job candidates. In the US, one data broker disclosed in a government filing that “they buy our health information, electronic health records, prescriptions, claims data, and they also put in information about our health from social media.” These “longitudinal” health profiles are then sold to thousand of clients, including the federal government. In the European Union, the GDPR was established, but public authorities and civil society struggle to apply its rules in concrete ways. Regulatory guidance seems not entirely complete. Information about millions of people is sold to corporate and governmental actors in both the US and Europe. Data brokers, and the profiling techniques used, are giving large institutions more visibility than...",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "8ea466faf79f594f1f4d356208cd627c",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/vectors",
    "t": "Attack vectors ",
    "c": "Attack vectors  Classification analysis  Classification analysis is a data mining technique that enables recognising patterns (recurring schemes) inside a dataset. It is considered an effective solution to improving marketing strategy performance, deleting superfluous information and creating subclasses. Real-world datasets, such as scientific publication datasets and social network datasets, contain interlinked entities and exhibit correlations among labels of the interlinked entities (for example, friendships and group memberships). Link-based classification can exploit such correlations in the link structure to identify private attributes. Group-based classifiers can be combined with auxiliary information to identify users in social networks (or to significantly reduce the set of possible candidates). Meaning that rather than tracking a user’s browser with cookies, it is possible to track a person. To determine the group membership of a user, well-known web browser history stealing attacks have been used: whenever a social network user visits a malicious website, this website can launch the de-anonymisation attack and learn the identity of its visitors. The similarity classifiers approach uses local features such as activity over time, text, geographic, and social features to form similarity classifiers that predict whether or not two accounts from two different social platforms are belonging to the same individual by deciding on similarities between them. Matching features  Cluster analysis enables identifying a given user or user group according to features, that can include age, geographic location, education level, etc. It is a data mining technique that is in use in marketing to segment a dataset and, for example, send a message to the right target for that product or service (young people, mothers, pensioners, etc.). The variable combinations are endless and make cluster analysis more or less selective according to the search requirements. Similarity is the underlying principle for making product recommendations (identifying people who are alike in terms of the products they have purchased or have liked). Online retailers such as Amazon use similarity to provide recommendations of similar products. When expressions like “People who like A also like B” appear, similarity has been applied. Similarity matching tries to recognise similar individuals based on known information about them. Similarity matching is also an approach where attacks rely on similar features between a target dataset and auxiliary information to perform the matching. For example, mobility traces (WiFi contacts, Instant Message contacts) can be used to find distance similarities that are then matched with the help of statistical predictors. Similarities can be matched between social data and mobility traces data, and between resume and tweets, and some techniques use node similarity to match graphs in social networks. Matching statistics maps datasets statistically and relies on the unique features of users’ data (intrinsic characteristics, such as interests and political views), to perform matching operations that can lead to users being identified and tracked. Graph matching  Graph matching is a network structure vector and the most common approach. It focuses on matching two graphs from the same target domain or two different domains. Privacy can be breached once its network structure is revealed, as a standard technique of re-identification can be developed based on that. Find the largest common sub-graph between a pair of ego nets Focus on common nodes of two graphs that are at 1-hop from the center Use the degree distribution of nodes and observe the 1-hop neighbourhood degree distribution of the common nodes, storing each node’s degrees in a list as a signature. If matching signatures are found between a pair of nodes from the two graphs, those nodes are considered to be the same. This simple version does not work with graphs where common nodes are 2-hops away from the centre, but n-hop algorithms have been developed and can de-anonymise more data. Naive anonymisation of social network graphs often uses deleting all identifying information of the users, while maintaining the original graph structure. Graph matching can start by creating a node (for example a user account) in a social graph and building up links with other nodes. Some call this graph matching expansion process “seed & grow”. When combined with link prediction it can give high accuracy and coverage for an attack. Active attacks in which the adversary registers a number of fake users (sybils) with the social network, allows for creating unique structural patterns that can be used used to re-identify the sybil nodes and other users after anonymisation. Studies showed that adding a small amount of noise to the published graph sufficed to mitigate such active attacks, but new robust active attacks merely see that as an optimisation problem for which various heuristics can be used. Graph matching can also start with threading. The threading method can be used for correlating sequential releases that are then matched. This works best in dynamic social networks that grow fast. In later research it was noted this can be used to detect users with multiple accounts (sybils). Trail re-identification  The trail re-identification approach was developed for linking genomic data to their identified users whose records are publicly available in various databases. The concept of trail re-identification includes de-anonymising users by collecting network data and then mapping their anonymised traces with IP addresses, matching IP addresses with Tor hidden services using traffic analysis, and tracking users by detecting their fingerprints in web browsers (visited web pages in the browser’s history). Sparsity-based  Sparse data share few relationships, but the activity stream of the target within anonymised sets of streams can be gathered from other users. Activity relationship mining consists of rules that link various aspects of two captured activity types and can help decide if two activities were probably achieved by the same individual or not. Existing sparsity-based techniques have been adapted to exploit mobile sensor data characteristics, indicating significant threats to user anonymity within shared mobile sensor data. Several studies looked at the advantages of sparsity for de-anonymisation. De-anonymisation could improve due to database sparsity and if the auxiliary information consists of values matching with rare attributes of a target database, then the de-anonymisation achieved is greater. It is not the sparsity, but in what way it is sparse that provides information. In 2017, the social network de-anonymisation problem was converted into a binary classification problem between node pairs. Using the spectral partition method, large sparse social networks were partitioned into a number of small sub graphs. The features of the network structure were used to train the random forest classifier. As a result, candidate node pairs from anonymous network and auxiliary network can be classified as matched pair by the random forest classifier. Resources  To Join or Not to Join: The Illusion of Privacy in Social Networks with Mixed Public and Private User Profiles , Elena Zheleva and Lise Getoor, 2009 A Practical Attack to De-Anonymize Social Network Users , Gilbert Wondracek, Thorsten Holz, Engin Kirda, Christopher Kruegel, 2010 De-anonymizing Users Across Heterogeneous Social Computing Platforms , Mohammed Korayem, David Crandall, 2013 Trail Re-Identification:Learning Who You Are From Where You Have Been , Bradley Malin et al., 2013 Trawling for Tor Hidden Services: Detection, Measurement, Deanonymization , Alex Biryukov, Ivan Pustogarov, Ralf-Philipp Weinmann, 2013 De-anonymizing Social Networks with Random Forest Classifier , Jiangtao Ma, Yaqiong Qiao, Guangwu Hu, Yongzhong Huang, 2017",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "b4177fddbeac352dd220784456b4eb18",
    "u": "https://green.tymyrddin.dev/docs/deanonymisation/impacts",
    "t": "Impacts ",
    "c": "Impacts  ↑ Data  One of the most often mentioned issues with personal information mined from an individual’s consumption behaviour for purposes of recommending products and/or services to that individual, is that it can cause pain and embarrassment to individuals, and it can deliver noise. What if you are permanently in a wheelchair and out of curiosity or for buying a family member or friend a gift, checked products online that someone in a wheelchair cannot use, and then get offered similar products on your screen for days? What if you are a teenage girl visiting a website that sells baby products, and the application of the company sends promotional baby products to your home address? In short, companies seem to think that if more information is disclosed and used, sales of products will automatically increase. Data gathered in large pools of information, is increasingly a focus of technology competition. Instead, better approaches on how to interpret data, models, and understanding the limitations of both in order to produce better output are required. Data without sound approaches becomes noise. Better Data != ↑ Data Better data does not mean more data, sometimes it means less (data cleansing, outlier removal, stratified sampling). Content-based features (or different features in general) might be able to improve accuracy in many cases, but not always. High bias situations (a model that is too simple to explain the data) will not benefit from more training examples, but might indeed benefit from more features. High variance situations (a model that is too complicated for the amount of data, the training error is much lower than the test error) leads to model over-fitting, and can be addressed by reducing the number of features, and by increasing the number of data points. Complex algorithms can limit the ability of scaling up to larger number of features. ↑ Bias and discrimination  Human agency and oversight: AI systems are to enable equitable societies by supporting human agency and fundamental rights, and not decrease, limit or misguide human autonomy. The models used are opaque, using them with real data is officially regulated in Europe (but public authorities and civil society struggle to apply its rules in concrete ways), and the results of the models are mostly incontestable, even when they introduce and reinforce bias and discrimination at every level (selection, confirmation, etc): A chatbot that became racist. Tay made it to the MIT Technology Review’s list of 2016’s biggest technology failures . HR resume/candidate screening applications that discriminate based on some characteristic (age, gender, religion, etc). If a marginalised person does not get a job because an employer receives a report that contains by the employer unwanted characteristics, he/she will not get the opportunity to gain respectability and independence. Instead, the vicious spiral continues. If a poor student cannot get a loan because a lending model deems him or her too risky (by virtue of where he/she lives), he/she is then cut off from the kind of education that could pull him/her out of poverty, and another vicious spiral continues. If DNA analysis companies start selling anonymised data to insurance companies they will be able to include it into their risk analysis. There will be a lot of biases, a lot of mistakes. On average nothing will change but there will be biased shifts in premiums in subgroups. In short, if your data belongs to a subgroup even if you do not share every characteristic of that subgroup you might be negatively impacted. Models favour the lucky and punish the underdogs. The dark side of Big Data. Yet recommending that humans should be involved in the decision-making processes also has to take into account that it is people that have the most bias. They create algorithms that are biased. Avoiding bias is hard. Techniques and checks to identify it is not so hard to make and critical thinking to rectify it is not that hard to learn either. But as with security in the past decades, it seems not a main concern of digital business-as-usual because it doesn’t make money. ↓ Competition  Datasets seem to be incredibly valuable to companies: Microsoft purchased LinkedIn for $26.2 billion last year. LinkedIn has about 467 million members (and their profiles and connections). IBM has acquired Truven Health (data on the cost and treatment of more than 200 million patients) for \\(2.6 billion and \\) 2 billion for the digital assets of the Weather Company. Google offers businesses a new software service to improve job finding and recruiting. Its data includes more than 17 million online job postings and the public profiles and résumés of more than 200 million people. Increasingly, data collection, analysis and distribution creates and shapes markets. If the big internet companies attract more users and advertisers, and gather more and more data, a powerful “network effect” may prevent users and advertisers from moving away from a dominant digital platform, like Google in search or Facebook in consumer social networks. As a result, people might be afforded less privacy than they would choose in a more competitive market. ↑ Surveillance and tracking  Every citizen on this planet is subject to some sort of tracking/surveillance. This includes information that does not, by itself, identify individuals, but sits in various databases (datasets) until data scientists use it for some purpose. The proximate reasons for the culture of surveillance are clear: Storage is cheap enough that we can keep everything. Computers are fast enough to examine this information, both in real time and retrospectively. Our daily activities are mediated with software that can easily be configured to record and report everything it sees upstream. But to fix surveillance, we have to address the underlying reasons that it exists. These are no mystery either. State surveillance is driven by fear. And corporate surveillance is driven by financial gain (which is also driven by fear). Data can be explicit or implicit. Explicit data consists of data users provide explicitly such as ratings and comments on products. Users have a choice whether to provide it or not. Implicit data does not need any extra action from the user. Examples of implicit data are order history/return history, cart events, page views, click through, and search logs. This data set is created for every user visiting an e-commerce/online business. Behavioural data is easy to collect because it can be extracted from a log of user activities and/or bought from data brokers. Tracking is categorised into first-party and third-party tracking. The user is the second-party. In first-party tracking, the tracking is performed by the site or application with which the user is directly interacting. In third-party tracking, the tracking is performed by a third party that tracks the user’s activity over time and across different devices and (digital or analogue) locations. Facebook tracks across sites via its Like button; each time a user visits a site that contains a Facebook Like button, Facebook collects this information, even if the user does not click on the button. In the first-party context, behavioural tracking and profiling is used to recommend products that are likely to be of interest to users. Amazon recommends products to online users based on individuals’ past behaviours (personalised recommendation), on past behaviours of similar users (social recommendation) and on searched items (item recommendation). With the rise of mobile phones, mobile applications track users’ locations and movement. Location information enables many useful services such as receiving driving directions and knowing where your kids are. And this information is also collected by marketers to improve profiling. This poses a threat to location privacy, as illustrated by iPhone and Android controversies. Increasingly, consumer devices are...",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "4fd2b57931c793b3c8950fc686d73284",
    "u": "https://green.tymyrddin.dev/docs/l-space/pervasivesurveillance",
    "t": "Pervasive surveillance ",
    "c": "Pervasive surveillance  Communication in a world of pervasive surveillance Sources and methods: Counter-strategies against pervasive surveillance architecture, Jacob R. Appelbaum, 2022 Resources reading list  Plenary vote on the “e-evidence package” Regulation and Directive on “European production and preservation orders for electronic evidence in criminal matters” and “legal representatives” , EDRi, 2023 The Coup We Are Not Talking  , Shoshana Zuboff, 2021 Of intelligence oversight and the challenge of surveillance corporatism , Peter Gill, 2020 The Psychology of Espionage , Dr. Ursula M. Wilder, 2017",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "e54568328cccb206e752234d119e6bc5",
    "u": "https://green.tymyrddin.dev/docs/l-space/thegreatoffshore",
    "t": "The Great Offshore ",
    "c": "The Great Offshore  Making fireworks go off in the privacy of the reader’s brain ALGOFFSHORE is a series of algorithmic flowcharts that documents various strategies of offshoring and tax optimization. The Sea is Glowing pays attention to the most singular and uncanny incarnations of the offshore phenomenon : Art freeports, Luxembourg space mining futuristic projects, Malta’s golden passports programs, seasteading experimental projects and Flags of convenience and the End of Life Flags. The Space Offshore dives into the futuristic activities of the offshore industry shed a crude light on the negotiations around space governance that happen today, far away from the public eye. Resources reading list  Learning. Using the library. Opening articles and books. Reading. More. loopholeforall , Paolo Cirio, Interview to be published in april 2021 in “THE GREAT OFFSHORE”, a collection of text on offshore, edited by RYBN.ORG. State to Stateless Machines: A Trajectory , James Bridle, 2019 Offshore Finance: How Capital Rules the World , Reijer Hendrikse and Rodrigo Fernandez, KU Leuven, 2019 Outside of Borders , Rachel O’Dwyer, 2019 A Utopia for Money: A visit to the secretive art warehouse at the Singapore airport , Max Haiven, 2017 The Revolution Will Be Digitized in Panama Papers Mossack Fonseca Tally , John Doe, 2016 You and me and the TCC: Finance and Urban Form , Brian Holmes The city and its double , Vera Tollmann & Boaz Levin, 2016 Duty-Free Art , Hito Steyerl, 2015 Caribbean mirage: Living in a blindspot of financial architecture , Femke Herregraven, 2010. Geographies of Avoidance , 2011, addresses the financial offshore system and avoidance of financial regulation, an index of a place that doesn’t want to be indexed. Hack back! , Phineas Fisher, with a translation in the anarchist library The Off-Shore Economist: Tactics , Brett Scott",
    "cat": "green",
    "type": "html"
  },
  {
    "objectID": "8ec52d89be69c36ad5ae59a774d6f1a7",
    "u": "https://green.tymyrddin.dev/docs/l-space/armstradelitigationmonitor",
    "t": "Arms Trade Litigation Monitor ",
    "c": "Arms Trade Litigation Monitor  “Peace?’ said Vetinari. ‘Ah, yes, defined as period of time to allow for preparation for the next war.” ~ Unseen Academicals The Arms Trade Litigation Monitor is a website which tracks and documents legal proceedings that seek accountability for arms transfers linked with armed conflict and humanitarian crisis globally. Resources reading list  Bendobrown: videos on maps, data & OSINT OSINTCurio.us Geolocation John Doe 29: Image From FBI Child Exploitation Case Geolocated to Turkey , Carlos Gonzales, 2021 Mahbere Dego: Clues to a Clifftop Massacre in Ethiopia , Bellingcat Investigation Team, 2021 How to Crack Complex Geolocation Challenges: A Case Study of the Mahibere Dego Massacre , Amnesty International Citizen Evidence Lab, Martyna Marciniak and Sam Dubberley, 2021. Image Forensics , Hany Farid, 2020 Grey is the new black: covert action and implausible deniability , Rory Cormac, Richard J. Aldrich, 2018 The Elephant in the Room: The International Arms Trade and the G7 , GLI Team, 2018",
    "cat": "green",
    "type": "html"
  }
]